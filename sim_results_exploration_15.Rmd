---
title: "Sim_results_exploration"
author: "Lisa KÃ¶hler"
date: "2024-04-01"
output: pdf_document
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, warnings = FALSE)

# libraries
library("tidyverse")
library("IsingSampler")
library("igraph")
library("ggplot2")
library("qgraph")
```

## Introduction

This master thesis investigates the psychometric properties of the sum score in network models. The sum score is a widely used measure under the latent variable view; however, we investigate its application to network models. This investigation involves the simulation of network models under various conditions to answer three sub-questions. Firstly, how do observed sum scores relate to the true sum scores of the data generating network models? Secondly, does Cronbach's alpha act as a lower bound for reliability in network models? Thirdly, investigating the lower bound theorem in more detail, is the lower bound assumption of uncorrelated errors met?

The code for data simulation is included in this repository in two parts: Sum_score_sim and Error_cor_sim. Sum_score_sim was used to generate all networks and data for sub-questions 1 and 2, and Error_cor_sim calculates error correlations from these networks for sub-question 3. In this code segment for 15-node networks we did not investigate sub-question 3. 

The data used in this file is data from 15-node networks. Files for 5 and 10-node networks are also included in the repository.

## Data assembly

```{r}
# load data
data_15 <- read.table("~/BDS-Master/Master thesis/R/Sim_data/Simulation_15_new.txt",
                   header = TRUE, sep = "")

# change Sw_0 edge weights
## SW_0 has no edges .: edge weight indication is misleading
data_15[data_15$model == "SW_0", "meanWeight"] <- 0

# reduce column number
## save thresholds as a 1x10 matrix
data_15 <- data_15 %>%
  rowwise() %>%
  mutate(tholds = matrix(c(tholds.1, tholds.2, tholds.3,  tholds.4, tholds.5, tholds.6,
                           tholds.7, tholds.8, tholds.9, tholds.10, tholds.11,
                           tholds.12, tholds.13,  tholds.14, tholds.15),
                         nrow = 1),
         .keep = "unused")
## save configurations as a 1x10 matrix
data_15 <- data_15 %>%
  rowwise() %>%
  mutate(config_o = matrix(c(config_o.1, config_o.2, config_o.3,  config_o.4,
                             config_o.5, config_o.6, config_o.7, config_o.8,
                             config_o.9, config_o.10, config_o.11, config_o.12,
                             config_o.13, config_o.14, config_o.15),
                           nrow = 1), 
         .keep = "unused")

# numeric connectivity
connectivity <- function(model) {
  if (model %in% c("CW", "SW_100")) {
    con <- 1
  } else if (model == "SW_75") {
    con <- 0.75
  } else if (model == "SW_50") {
    con <- 0.5
  } else if (model == "SW_25") {
    con <- 0.25
  } else {
    con <- 0
  }
  return(con)
}

data_15 <- data_15 %>% mutate(con = connectivity(model))
```

We also create a data frame that alters certain columns, which are used to create our plots.

```{r}
# create data for plots
data_15_plot <- data_15

# making factor variables
## these become the labels in the facet grid
data_15_plot$encoding <- factor(data_15$encoding,
                             levels = c(-1, 0),
                             labels = paste0(c("Symmetric", "Binary"), " Encoding"))

data_15_plot$model <- factor(data_15$model,
                          levels = c("CW", "SW_100", "SW_75", "SW_50", "SW_25", "SW_0"),
                          labels = c("CW", "SW_100", "SW_75", "SW_50", "SW_25", "SW_0"))

data_15_plot$factorThresholds <- factor(data_15$thresholds,
                               levels = c(-3, -2, -1, 0, 1),
                               labels = paste0("\u03c4", ": ", c(-3, -2, -1, 0, 1)))

data_15_plot$factorWeight <- factor(data_15$meanWeight,
                                 levels = c(0, 0.25, 0.5, 0.75, 1),
                                 labels = paste0("\u03c9: ", c(0, 0.25, 0.5, 0.75, 1)))
```


## Inspect variation 

First we will have a look at the amount of variation of the observed and expected sum scores of each of our conditions.

```{r}
# calculate variation per condition
condition_cols <- c("model", "encoding", "thresholds", "meanWeight")
data_15 %>%
  group_by(across(all_of(condition_cols))) %>%
  summarize(sd_o = sd(sum_o),
            min_o = min(sum_o),
            max_o = max(sum_o)) %>%
  arrange(encoding, desc(sd_o))

# calculate variation averaging over thresholds
data_15 %>%
  group_by(across(all_of(c("model", "encoding", "meanWeight")))) %>%
  summarize(sd_o = sd(sum_o),
            min_o = min(sum_o),
            max_o = max(sum_o)) %>%
  arrange(encoding, desc(sd_o))

# calculate variation averaging over weights
data_15 %>%
  group_by(across(all_of(c("model", "encoding", "thresholds")))) %>%
  summarize(sd_o = sd(sum_o),
            min_o = min(sum_o),
            max_o = max(sum_o)) %>%
  arrange(encoding, desc(sd_o))
```

This is easier to inspect visually, so we will plot our observed and expected sum scores per condition.

```{r}
# observed  sum score
graphs_sum_o_15 <- list()
for (enc in sort(unique(data_15_plot$encoding))){
  sub <- data_15_plot %>% filter(encoding == enc)

  graphs_sum_o_15 <- c(graphs_sum_o_15, list(
    ggplot(sub, aes(x = sum_o, fill = model)) +
      geom_histogram() +
      facet_grid(factorWeight ~ factorThresholds) +
      scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
      scale_y_continuous(trans = "log10") +
      scale_fill_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                   "#0072B2", "#56B4E9", "#CC79A7")) +
      theme_bw() +
      ggtitle(enc) +
      labs(x = "Observed Sum Score", y = "Frequency", fill = "Model") +
      theme(legend.position = "none",
            strip.text = element_text(size = 12),
            axis.text = element_text(size = 12),
            axis.title = element_text(size = 14),
            plot.title = element_text(size = 14))
  ))
}

# combine plots
graphs_sum_o_15[[1]] + graphs_sum_o_15[[2]] +
  plot_layout(nrow = 2, guides = "collect") &
  theme(legend.position = 'bottom') &
  guides(fill = guide_legend(nrow = 1))
```


## Sub-question 1: Under what conditions are the current and expected sum score related?

```{r}
# calculate correlation over all conditions
cor(data_15$sum_e, data_15$sum_o)
data_15 %>% group_by(encoding) %>% summarise(corr = cor(sum_e, sum_o))
data_15 %>%
  group_by(across(all_of(c("encoding", "meanWeight")))) %>%
  summarise(corr = cor(sum_e, sum_o)) %>%
  arrange(encoding, desc(corr))

# plot correlation over all condition
ggplot(data_15_plot,
       aes(x = sum_o, y = sum_e)) +
  geom_point() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(cols = vars(encoding), scales = "free") +
  theme_bw() +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")

# add jitter to see amount of points more clearly
ggplot(data_15_plot,
       aes(x = sum_o, y = sum_e)) +
  geom_jitter() +
  scale_x_continuous(breaks = seq(-15, 15, by = 5),
                     minor_breaks = seq(-15, 15, by = 1)) +
  facet_grid(cols = vars(encoding), scales = "free") +
  theme_bw() +
  theme(strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14)) +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")

# inspect plots at lower edge weights
ggplot(data_15_plot[data_15_plot$encoding == "Symmetric Encoding",],
       aes(x = sum_o, y = sum_e)) +
  geom_jitter() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(rows = vars(paste0("\u03c9: ", meanWeight)), scales = "free") +
  theme_bw() +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")

ggplot(data_15_plot[data_15_plot$encoding == "Symmetric Encoding",],
       aes(x = sum_o, y = sum_e)) +
  geom_jitter() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(rows = vars(paste0("con: ", con)), scales = "free") +
  theme_bw() +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")

ggplot(data_15_plot[data_15_plot$encoding == "Symmetric Encoding",],
       aes(x = sum_o, y = sum_e)) +
  geom_jitter() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(paste0("con: ", con) ~ paste0("\u03c9: ", meanWeight), scales = "free") +
  theme_bw() +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")
```

This is a look into the correlation between the observed and expected sum score. The jitter on the second graph helps see the amount of points more clearly, although observes sum scores can only have integer values as demonstrated in the first plot.

```{r}
# correlation table
condition_cols <- c("model", "encoding", "factorThresholds", "meanWeight")
cor_15 <- data_15_plot %>%
  group_by(across(all_of(condition_cols))) %>%
  summarize(corr = cor(sum_e, sum_o),
            thresholds = mean(thresholds), # we want to keep the threshold column
            con = mean(con),
            size = 15) %>%
  arrange(desc(corr))
cor_15
```

Let's investigate these correlations further.

```{r, warnings = FALSE}
# plot correlation per condition
ggplot(cor_15,
       aes(x = meanWeight, y = corr, colour = model)) +
  geom_line() +
  geom_point() +
  facet_grid(factorThresholds ~ encoding) +
  geom_segment(aes(y = corr, x = 0, xend = 1, yend = corr),
               data = cor_15[cor_15$model == "SW_0",]) +
  #theme(legend.position = "bottom") +
  scale_color_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                "#0072B2", "#56B4E9", "#CC79A7")) +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.25)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2),
                     minor_breaks = seq(0, 1, by = 0.1)) +
  xlab("Edge weight") +
  ylab("Correlation")
```

Let's average over some conditions to see the effects of thresholds and weights in isolation.

```{r}
# correlation averaging over thresholds
cor_15_w <- data_15_plot %>%
  group_by(across(all_of(c("model", "encoding", "meanWeight")))) %>%
  summarize(corr = cor(sum_e, sum_o)) %>%
  arrange(desc(corr))

# plot
cor_15_plots <- list()
cor_15_plots[[1]] <- ggplot(cor_15_w,
                         aes(x = meanWeight, y = corr, colour = model)) +
  geom_line() +
  geom_point() +
  facet_grid(cols = vars(encoding), scales = "free") +
  geom_segment(aes(y = corr, x = 0, xend = 1, yend = corr),
               data = cor_15_w[cor_15_w$model == "SW_0",], color = "#CC79A7") +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.25)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2),
                     minor_breaks = seq(0, 1, by = 0.1)) +
  scale_color_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                "#0072B2", "#56B4E9", "#CC79A7")) +
  labs(x = "Edge weight", y = "Correlation", color = "Model") +
  theme(legend.position = "none", 
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))


# correlation averaging over weights
cor_15_t <- data_15_plot %>%
  group_by(across(all_of(c("model", "encoding", "thresholds")))) %>%
  summarize(corr = cor(sum_e, sum_o)) %>%
  arrange(desc(corr))

# plot
cor_15_plots[[2]] <- ggplot(cor_15_t,
                         aes(x = thresholds, y = corr, colour = model)) +
  geom_line() +
  geom_point() +
  facet_grid(cols = vars(encoding), scales = "free") +
  theme_bw() +
  scale_x_continuous(breaks = seq(-3, 1, by = 1)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2),
                     minor_breaks = seq(0, 1, by = 0.1)) +
  scale_color_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                "#0072B2", "#56B4E9", "#CC79A7")) +
  labs(x = "Thresholds", y = "Correlation", color = "Model") +
  theme(legend.position = "none", 
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

# combine plots
cor_15_plots[[1]] + cor_15_plots[[2]] +
  plot_layout(nrow = 2, guides = "collect") &
  theme(legend.position = 'bottom') &
  guides(color = guide_legend(nrow = 1))
```


## Sub-question 2: under what conditions does cronbachâs alpha hold as a lower bound for reliability?

We first create a data frame that includes statistics such as reliability, Cronbach's alpha, and overshoot. Overshoot is the amount by which alpha overestimates reliabiity.

```{r}
# calculate reliability
rel_15 <- data_15_plot %>%
  group_by(across(all_of(condition_cols))) %>%
  summarize(reliability = cor(sum_e, sum_o) ^ 2,
            alpha = cronbach.alpha(data.frame(config_o))$alpha, 
            dif = reliability - alpha,
            lower_bound = alpha <= reliability,
            thresholds = mean(thresholds), # keep the threshold column
            con = mean(con), # keep the connectivity column
            size = 15) %>%
  arrange(desc(dif))

# reliability ranges
rel_15[, "reliability"] %>% range(na.rm = TRUE)
rel_15[, "alpha"] %>% range(na.rm = TRUE)

# box plot
ggplot(rel_15, aes(y = encoding, x = reliability)) + 
  geom_boxplot() +
  theme_bw() +
  labs(x = "Reliability", y = "Encoding") +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

# inspect lower bound condition met
rel_15 %>% filter(!is.na(lower_bound))
```

Let's average over some conditions to see the effects of thresholds and weights in isolation.

```{r}
# calculate reliability average over thresholds
rel_15_w <- data_15_plot %>%
  group_by(across(all_of(c("model", "encoding", "meanWeight")))) %>%
  summarize(reliability = cor(sum_e, sum_o) ^ 2,
            alpha = cronbach.alpha(data.frame(config_o))$alpha, 
            overshoot = alpha - reliability,
            lower_bound = alpha <= reliability) %>%
  arrange(desc(overshoot))

# reliability ranges
rel_15_w[, "reliability"] %>% range(na.rm = TRUE)
rel_15_w[, "alpha"] %>% range(na.rm = TRUE)

# inspect lower bound condition met
rel_15_w %>% filter(!is.na(lower_bound))

# calculate reliability average over thresholds
rel_15_t <- data_15_plot %>%
  group_by(across(all_of(c("model", "encoding", "thresholds")))) %>%
  summarize(reliability = cor(sum_e, sum_o) ^ 2,
            alpha = cronbach.alpha(data.frame(config_o))$alpha, 
            overshoot = alpha - reliability,
            lower_bound = alpha <= reliability) %>%
  arrange(desc(overshoot))

# reliability ranges
rel_15_t[, "reliability"] %>% range(na.rm = TRUE)
rel_15_t[, "alpha"] %>% range(na.rm = TRUE)

# inspect lower bound condition met
rel_15_t %>% filter(!is.na(lower_bound))
```

Let's plot this for a closer look at the trends.

```{r}
ggplot(rel_15[!is.na(rel_15$reliability), ],
       aes(x = meanWeight, y = overshoot, colour = model)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0, linewidth = .8) +
  facet_grid(factorThresholds ~ encoding) +
  geom_segment(aes(y = overshoot, x = 0, xend = 1, yend = overshoot),
               data = rel_15[rel_15$model == "SW_0",]) +
  theme(legend.position = "bottom") +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.25)) +
  scale_y_continuous(breaks = seq(-1, 3, by = 1),
                     minor_breaks = seq(-1, 3, by = 0.5)) +
  xlab("Edge weight") +
  ylab("Reliability - alpha")
```

As before we inspect the influence of weights and thresholds separately.

```{r}
rel_15_plots <- list()
# Weight trends
rel_15_plots[[1]] <- ggplot(rel_15_w,
                         aes(x = meanWeight, y = overshoot, colour = model)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0, linewidth = .8) +
  facet_grid(cols = vars(encoding), scales = "free") +
  geom_segment(aes(y = overshoot, x = 0, xend = 1, yend = overshoot),
               data = rel_15_w[rel_15_w$model == "SW_0",], color = "#CC79A7") +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.25)) +
  scale_y_continuous(breaks = seq(-1, 1, by = 0.5),
                     minor_breaks = seq(-1, 1, by = 0.2)) +
      scale_color_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                   "#0072B2", "#56B4E9", "#CC79A7")) +
  theme_bw() +
  labs(x = "Edge Weight", y = "Overshoot", color = "Model") +
  theme(legend.position = "none",
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

# Threshold trends
rel_15_plots[[2]] <- ggplot(rel_15_t,
                         aes(x = thresholds, y = overshoot, colour = model)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0, linewidth = .8) +
  facet_grid(cols = vars(encoding), scales = "free") +
  theme_bw() +
  scale_x_continuous(breaks = seq(-3, 1, by = 1)) +
  scale_y_continuous(breaks = seq(-1, 1, by = 0.5),
                     minor_breaks = seq(-1, 1, by = 0.2)) +
      scale_color_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                   "#0072B2", "#56B4E9", "#CC79A7")) +
  theme_bw() +
  labs(x = "Thresholds", y = "Overshoot", color = "Model") +
  theme(legend.position = "none",
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

# combine plots
rel_15_plots[[1]] + rel_15_plots[[2]] +
  plot_layout(nrow = 2, guides = "collect") &
  theme(legend.position = 'bottom') &
  guides(color = guide_legend(nrow = 1))
```
