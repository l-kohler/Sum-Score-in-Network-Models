---
title: "Sim_results_exploration"
author: "Lisa Köhler"
date: "2024-04-01"
output: pdf_document
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, warnings = FALSE)

# libraries
library("tidyverse")
library("IsingSampler")
library("igraph")
library("ggplot2")
library("qgraph")
library("stats")
library("patchwork")
```

## Introduction

This master thesis investigates the psychometric properties of the sum score in network models. The sum score is a widely used measure under the latent variable view; however, we investigate its application to network models. This investigation involves the simulation of network models under various conditions to answer three sub-questions. Firstly, how do observed sum scores relate to the true sum scores of the data generating network models? Secondly, does Cronbach's alpha act as a lower bound for reliability in network models? Thirdly, investigating the lower bound theorem in more detail, is the lower bound assumption of uncorrelated errors met?

The code for data simulation is included in this repository in two parts: Sum_score_sim and Error_cor_sim. Sum_score_sim was used to generate all networks and data for sub-questions 1 and 2, and Error_cor_sim calculates error correlations from these networks for sub-question 3. Both these files were run to generate the data used in this file.

The data used in this file is data from 10-node networks. Files for 5 and 15-node networks are also included in the repository.

## Data assembly

```{r}
# load data
data <- read.table("~/BDS-Master/Master thesis/R/Sim_data/Simulation_10_error_cor.txt",
                   header = TRUE, sep = "")

# change Sw_0 edge weights
## SW_0 has no edges .: edge weight indication is misleading
data[data$model == "SW_0", "meanWeight"] <- 0

# reduce column number
## save thresholds as a 1x10 matrix
data <- data %>%
  rowwise() %>%
  mutate(tholds = matrix(c(tholds.1, tholds.2, tholds.3,  tholds.4, tholds.5, tholds.6,
                                  tholds.7, tholds.8, tholds.9, tholds.10),
                         nrow = 1),
         .keep = "unused")
## save configurations as a 1x10 matrix
data <- data %>%
  rowwise() %>%
  mutate(config_o = matrix(c(config_o.1, config_o.2, config_o.3,  config_o.4,
                                    config_o.5, config_o.6, config_o.7, config_o.8,
                                    config_o.9, config_o.10),
                           nrow = 1), 
         .keep = "unused")

# numeric connectivity
connectivity <- function(model) {
  if (model %in% c("CW", "SW_100")) {
    con <- 1
  } else if (model == "SW_75") {
    con <- 0.75
  } else if (model == "SW_50") {
    con <- 0.5
  } else if (model == "SW_25") {
    con <- 0.25
  } else {
    con <- 0
  }
  return(con)
}

data <- data %>% mutate(con = connectivity(model))

# add networks
## prepare a column to receive matrix values
# data <- data %>% mutate(network = I(list(matrix(nrow = 10, ncol = 10))))
# ## add network matrices
# for (i in 1:nrow(data)) {
#   network <- read.table(paste0("~/BDS-Master/Master thesis/R/Networks/network_new/network_10_", i, ".txt"))
#   data[[i, "network"]] <- I(list(network))
#}
```


We also create a data frame that alters certain columns, which are used to create our plots.

```{r}
# create data for plots
data_plot <- data

# making factor variables
## these become the labels in the facet grid
data_plot$encoding <- factor(data$encoding,
                             levels = c(-1, 0),
                             labels = paste0(c("Symmetric", "Binary"), " Encoding"))

data_plot$model <- factor(data$model,
                          levels = c("CW", "SW_100", "SW_75", "SW_50", "SW_25", "SW_0"),
                          labels = c("CW", "SW_100", "SW_75", "SW_50", "SW_25", "SW_0"))

data_plot$factorThresholds <- factor(data$thresholds,
                               levels = c(-3, -2, -1, 0, 1),
                               labels = paste0("\u03c4", ": ", c(-3, -2, -1, 0, 1)))

data_plot$factorWeight <- factor(data$meanWeight,
                                 levels = c(0, 0.25, 0.5, 0.75, 1),
                                 labels = paste0("\u03c9: ", c(0, 0.25, 0.5, 0.75, 1)))
```


## Inspect variation 

First we will have a look at the amount of variation of the observed sum scores of each of our conditions.

```{r}
# calculate variation per condition
condition_cols <- c("model", "encoding", "thresholds", "meanWeight")
data %>%
  group_by(across(all_of(condition_cols))) %>%
  summarize(sd_o = sd(sum_o),
            min_o = min(sum_o),
            max_o = max(sum_o)) %>%
  arrange(encoding, desc(sd_o))

# calculate variation averaging over thresholds
data %>%
  group_by(across(all_of(c("model", "encoding", "meanWeight")))) %>%
  summarize(sd_o = sd(sum_o),
            min_o = min(sum_o),
            max_o = max(sum_o)) %>%
  arrange(encoding, desc(sd_o))

# calculate variation averaging over weights
data %>%
  group_by(across(all_of(c("model", "encoding", "thresholds")))) %>%
  summarize(sd_o = sd(sum_o),
            min_o = min(sum_o),
            max_o = max(sum_o)) %>%
  arrange(encoding, desc(sd_o))
```


This is easier to inspect visually, so we will plot our observed and expected sum scores per condition.

```{r}
# expected  sum score
graphs_sum_e <- list()
for (enc in sort(unique(data_plot$encoding))){
  sub <- data_plot %>% filter(encoding == enc)

  graphs_sum_e <- c(graphs_sum_e, list(
    ggplot(sub, aes(x = sum_e, fill = model)) +
      geom_histogram() +
      facet_grid(factorWeight ~ factorThresholds) +
      scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
      #scale_y_continuous(trans = "log10") +
      scale_fill_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                   "#0072B2", "#56B4E9", "#CC79A7")) +
      theme_bw() +
      ggtitle(enc) +
      labs(x = "Expected Sum Score", y = "Frequency", fill = "Model") +
      theme(legend.position = "none",
            strip.text = element_text(size = 12),
            axis.text = element_text(size = 12),
            axis.title = element_text(size = 14),
            plot.title = element_text(size = 14))
  ))
}

graphs_sum_e[[1]] + graphs_sum_e[[2]] +
  plot_layout(nrow = 2, guides = "collect") &
  theme(legend.position = 'bottom') &
  guides(fill = guide_legend(nrow = 1))

# observed  sum score
graphs_sum_o <- list()
for (enc in sort(unique(data_plot$encoding))){
  sub <- data_plot %>% filter(encoding == enc)

  graphs_sum_o <- c(graphs_sum_o, list(
    ggplot(sub, aes(x = sum_o, fill = model)) +
      geom_histogram() +
      facet_grid(factorWeight ~ factorThresholds) +
      scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
      scale_y_continuous(trans = "log10") +
      scale_fill_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                   "#0072B2", "#56B4E9", "#CC79A7")) +
      theme_bw() +
      ggtitle(enc) +
      labs(x = "Observed Sum Score", y = "Frequency", fill = "Model") +
      theme(legend.position = "none",
            strip.text = element_text(size = 12),
            axis.text = element_text(size = 12),
            axis.title = element_text(size = 14),
            plot.title = element_text(size = 14))
  ))
}

# combine plots
graphs_sum_o[[1]] + graphs_sum_o[[2]] +
  plot_layout(nrow = 2, guides = "collect") &
  theme(legend.position = 'bottom') &
  guides(fill = guide_legend(nrow = 1))
```


## Sub-question 1: Under what conditions are the current and expected sum score related?

```{r}
# calculate correlation over all conditions
cor(data$sum_e, data$sum_o)
data %>% group_by(encoding) %>% summarise(corr = cor.test(sum_e, sum_o)$estimate,
                                          p = cor.test(sum_e, sum_o)$p.value,
                                          df = cor.test(sum_e, sum_o)$parameter)
data %>%
  group_by(across(all_of(c("encoding", "meanWeight")))) %>%
  summarise(corr = cor.test(sum_e, sum_o)$estimate,
            p = cor.test(sum_e, sum_o)$p.value,
            df = cor.test(sum_e, sum_o)$parameter) %>%
  arrange(encoding, desc(corr))

# plot correlation over all condition
ggplot(data_plot,
       aes(x = sum_o, y = sum_e)) +
  geom_point() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(cols = vars(encoding), scales = "free") +
  theme_bw() +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")

# add jitter to see amount of points more clearly
ggplot(data_plot,
       aes(x = sum_o, y = sum_e)) +
  geom_jitter() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(cols = vars(encoding), scales = "free") +
  theme_bw() +
  theme(strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14)) +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")

# inspect symmetric encoding correlations per edge weights
ggplot(data_plot[data_plot$encoding == "Symmetric Encoding",],
       aes(x = sum_o, y = sum_e)) +
  geom_jitter() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(rows = vars(paste0("\u03c9: ", meanWeight)), scales = "free") +
  theme_bw() +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")

ggplot(data_plot[data_plot$encoding == "Symmetric Encoding",],
       aes(x = sum_o, y = sum_e)) +
  geom_jitter() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(rows = vars(paste0("con: ", con)), scales = "free") +
  theme_bw() +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")

ggplot(data_plot[data_plot$encoding == "Symmetric Encoding",],
       aes(x = sum_o, y = sum_e)) +
  geom_jitter() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(paste0("con: ", con) ~ paste0("\u03c9: ", meanWeight), scales = "free") +
  theme_bw() +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")
```

This is a look into the correlation between the observed and expected sum score. The jitter on the second graph helps see the amount of points more clearly, although observes sum scores can only have integer values as demonstrated in the first plot.

```{r}
# correlation table
condition_cols <- c("model", "encoding", "factorThresholds", "meanWeight")
cor <- data_plot %>%
  group_by(across(all_of(condition_cols))) %>%
  summarize(corr = cor(sum_e, sum_o),
            thresholds = mean(thresholds), # keep the threshold column
            con = mean(con), # keep the connectivity column
            size = 10) %>%
  arrange(desc(corr))
cor
```

Let's investigate these correlations further.

```{r, warnings = FALSE}
# plot correlation per condition
ggplot(cor,
       aes(x = meanWeight, y = corr, colour = model)) +
  geom_line() +
  geom_point() +
  facet_grid(factorThresholds ~ encoding) +
  geom_segment(aes(y = corr, x = 0, xend = 1, yend = corr),
               data = cor[cor$model == "SW_0",]) +
  #theme(legend.position = "bottom") +
  scale_color_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                "#0072B2", "#56B4E9", "#CC79A7")) +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.25)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2),
                     minor_breaks = seq(0, 1, by = 0.1)) +
  xlab("Edge weight") +
  ylab("Correlation")
```

Let's average over some conditions to see the effects of thresholds and weights in isolation.

```{r}
# correlation averaging over thresholds
cor_w <- data_plot %>%
  group_by(across(all_of(c("model", "encoding", "meanWeight")))) %>%
  summarize(corr = cor(sum_e, sum_o)) %>%
  arrange(desc(corr))

# plot
cor_plots <- list()
cor_plots[[1]] <- ggplot(cor_w,
                         aes(x = meanWeight, y = corr, colour = model)) +
  geom_line() +
  geom_point() +
  facet_grid(cols = vars(encoding), scales = "free") +
  geom_segment(aes(y = corr, x = 0, xend = 1, yend = corr),
               data = cor_w[cor_w$model == "SW_0",], color = "#CC79A7") +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.25)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2),
                     minor_breaks = seq(0, 1, by = 0.1)) +
  scale_color_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                "#0072B2", "#56B4E9", "#CC79A7")) +
  labs(x = "Edge weight", y = "Correlation", color = "Model") +
  theme(legend.position = "none", 
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))


# correlation averaging over weights
cor_t <- data_plot %>%
  group_by(across(all_of(c("model", "encoding", "thresholds")))) %>%
  summarize(corr = cor(sum_e, sum_o)) %>%
  arrange(desc(corr))

# plot
cor_plots[[2]] <- ggplot(cor_t,
                         aes(x = thresholds, y = corr, colour = model)) +
  geom_line() +
  geom_point() +
  facet_grid(cols = vars(encoding), scales = "free") +
  theme_bw() +
  scale_x_continuous(breaks = seq(-3, 1, by = 1)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2),
                     minor_breaks = seq(0, 1, by = 0.1)) +
  scale_color_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                "#0072B2", "#56B4E9", "#CC79A7")) +
  labs(x = "Thresholds", y = "Correlation", color = "Model") +
  theme(legend.position = "none", 
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

# combine plots
cor_plots[[1]] + cor_plots[[2]] +
  plot_layout(nrow = 2, guides = "collect") &
  theme(legend.position = 'bottom') &
  guides(color = guide_legend(nrow = 1))
```


## Sub-question 2: under what conditions does cronbach’s alpha hold as a lower bound for reliability?

We first create a data frame that includes statistics such as reliability, Cronbach's alpha, and overshoot. Overshoot is the amount by which alpha overestimates reliabiity.

```{r}
# calculate reliability
rel <- data_plot %>%
  group_by(across(all_of(condition_cols))) %>%
  summarize(reliability = cor(sum_e, sum_o) ^ 2,
            alpha = cronbach.alpha(data.frame(config_o))$alpha, 
            overshoot = alpha - reliability,
            lower_bound = alpha <= reliability, # is the lower bound property met?
            thresholds = mean(thresholds), # keep the threshold column
            error_cor = mean(error_corr_M), # mean error correlations
            con = mean(con), # keep the threshold column
            size = 10) %>%
  arrange(overshoot)

# reliability ranges
rel[rel$encoding == "Binary Encoding", "reliability"] %>% range(na.rm = TRUE)
rel[rel$encoding == "Symmetric Encoding", "reliability"] %>% range(na.rm = TRUE)

rel[rel$encoding == "Binary Encoding", "alpha"] %>% range(na.rm = TRUE)
rel[rel$encoding == "Symmetric Encoding", "alpha"] %>% range(na.rm = TRUE)

# box plot
ggplot(rel, aes(y = encoding, x = reliability)) + 
  geom_boxplot() +
  theme_bw() +
  labs(x = "Reliability", y = "Encoding") +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

# inspect lower bound condition met
rel %>% filter(!is.na(lower_bound))
```

Let's average over some conditions to see the effects of thresholds and weights in isolation.

```{r}
# calculate reliability average over thresholds
rel_w <- data_plot %>%
  group_by(across(all_of(c("model", "encoding", "meanWeight")))) %>%
  summarize(reliability = cor(sum_e, sum_o) ^ 2,
            alpha = cronbach.alpha(data.frame(config_o))$alpha, 
            overshoot = alpha - reliability,
            lower_bound = alpha <= reliability) %>%
  arrange(overshoot)

# reliability ranges
rel_w[rel_w$encoding == "Binary Encoding", "reliability"] %>% range(na.rm = TRUE)
rel_w[rel_w$encoding == "Symmetric Encoding", "reliability"] %>% range(na.rm = TRUE)
#rel_w[, "alpha"] %>% range(na.rm = TRUE)

# inspect lower bound condition met
rel_w %>% filter(!is.na(lower_bound))

# calculate reliability average over thresholds
rel_t <- data_plot %>%
  group_by(across(all_of(c("model", "encoding", "thresholds")))) %>%
  summarize(reliability = cor(sum_e, sum_o) ^ 2,
            alpha = cronbach.alpha(data.frame(config_o))$alpha, 
            overshoot = alpha - reliability,
            lower_bound = alpha <= reliability) %>%
  arrange(overshoot)

# reliability ranges
rel_t[rel_t$encoding == "Binary Encoding", "reliability"] %>% range(na.rm = TRUE)
rel_t[rel_t$encoding == "Symmetric Encoding", "reliability"] %>% range(na.rm = TRUE)
#rel_t[, "alpha"] %>% range(na.rm = TRUE)

# inspect lower bound condition met
rel_t %>% filter(!is.na(lower_bound))
```

Let's plot this for a closer look at the trends.

```{r}
ggplot(rel,
       aes(x = meanWeight, y = overshoot, colour = model)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0, linewidth = .8) +
  facet_grid(factorThresholds ~ encoding) +
  geom_segment(aes(y = overshoot, x = 0, xend = 1, yend = overshoot),
               data = rel[rel$model == "SW_0",], color = "#CC79A7") +
  theme(legend.position = "bottom") +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.25)) +
  scale_y_continuous(breaks = seq(-1, 1, by = 0.5),
                     minor_breaks = seq(-1, 1, by = 0.2)) +
      scale_fill_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                   "#0072B2", "#56B4E9", "#CC79A7")) +
  theme_bw() +
  ggtitle(enc) +
  labs(x = "Edge Weight", y = "Reliability - Cronbach's alpha", color = "Model") +
  theme(legend.position = "bottom",
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14)) +
  guides(color = guide_legend(nrow = 1))
```

As before we inspect the influence of weights and thresholds seperately.

```{r}
rel_plots <- list()
# Weight trends
rel_plots[[1]] <- ggplot(rel_w,
                         aes(x = meanWeight, y = overshoot, colour = model)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0, linewidth = .8) +
  facet_grid(cols = vars(encoding), scales = "free") +
  geom_segment(aes(y = overshoot, x = 0, xend = 1, yend = overshoot),
               data = rel_w[rel_w$model == "SW_0",], color = "#CC79A7") +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.25)) +
  scale_y_continuous(breaks = seq(-1, 1, by = 0.5),
                     minor_breaks = seq(-1, 1, by = 0.2)) +
      scale_color_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                   "#0072B2", "#56B4E9", "#CC79A7")) +
  theme_bw() +
  labs(x = "Edge Weight", y = "Overshoot", color = "Model") +
  theme(legend.position = "none",
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

# Threshold trends
rel_plots[[2]] <- ggplot(rel_t,
                         aes(x = thresholds, y = overshoot, colour = model)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0, linewidth = .8) +
  facet_grid(cols = vars(encoding), scales = "free") +
  theme_bw() +
  scale_x_continuous(breaks = seq(-3, 1, by = 1)) +
  scale_y_continuous(breaks = seq(-1, 1, by = 0.5),
                     minor_breaks = seq(-1, 1, by = 0.2)) +
      scale_color_manual(values = c("#D55E00", "#E69F00", "#009E73",
                                   "#0072B2", "#56B4E9", "#CC79A7")) +
  theme_bw() +
  labs(x = "Thresholds", y = "Overshoot", color = "Model") +
  theme(legend.position = "none",
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

# combine plots
rel_plots[[1]] + rel_plots[[2]] +
  plot_layout(nrow = 2, guides = "collect") &
  theme(legend.position = 'bottom') &
  guides(color = guide_legend(nrow = 1))
```


## Sub-question 3: under what conditions is the assumption of uncorrelated errors met? And how does this influence cronbach’s alpha?

Let's first have a look at the relationship between overshoot and error correlations.

```{r}
# Binary encoding
cor(rel[rel$encoding == "Binary Encoding", "overshoot"],
    rel[rel$encoding == "Binary Encoding", "error_cor"])
# Symmetric encoding
cor(rel[rel$encoding == "Symmetric Encoding", "overshoot"],
    rel[rel$encoding == "Symmetric Encoding", "error_cor"], 
    use = "pairwise.complete.obs")
```

Which conditions have the highest error correlations?

```{r}
rel %>%
  arrange(error_cor)
```

We plot these trends to inspect them more easily.

```{r}
# plot
ggplot(rel,
       aes(x = error_cor, y = overshoot)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  theme_bw() +
  scale_x_continuous(breaks = seq(-1, 1, by = 0.2),
                     minor_breaks = seq(-1, 1, by = 0.1)) +
  scale_y_continuous(breaks = seq(-1, 1, by = 0.2),
                     minor_breaks = seq(-1, 1, by = 0.1)) +
  xlab("Mean Error Correlation") +
  ylab("Overshoot") +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

# split plot by encoding
ggplot(rel,
       aes(x = error_cor, y = overshoot, color = model)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = .2),
                     minor_breaks = seq(0, 1, by = 0.05)) +
  facet_grid(cols = vars(encoding), scales = "free") +
  scale_color_manual(name = "Models",
                     values = rep(c("#D55E00", "black"), c(1, 5))) + 
  labs(x = "Mean Error Correlation", y = "Overshoot") +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14),
        legend.position = "none")

## view plot without outliers
### we remove outliers by restricting the range of error correlations
ggplot(rel[rel$error_cor < .15 & !is.na(rel$error_cor),],
       aes(x = error_cor, y = overshoot, color = model)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red") +
  theme_bw() +
  facet_grid(cols = vars(encoding), scales = "free") +
  scale_color_manual(name = "Models",
                     values = rep(c("#D55E00", "black"), c(1, 5))) + 
  labs(x = "Mean Error Correlation", y = "Overshoot") +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14),
        legend.position = "bottom")
```
