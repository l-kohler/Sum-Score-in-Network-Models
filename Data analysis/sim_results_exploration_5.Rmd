---
title: "Sim_results_exploration"
author: "Lisa Köhler"
date: "2024-04-01"
output: pdf_document
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, warnings = FALSE)

# libraries
library("tidyverse")
library("IsingSampler")
library("igraph")
library("ggplot2")
library("qgraph")
```

## Introduction

This master thesis investigates the psychometric properties of the sum score in network models. The sum score is a widely used measure under the latent variable view; however, we investigate its application to network models. This investigation involves the simulation of network models under various conditions to answer three sub-questions. Firstly, how do observed sum scores relate to the true sum scores of the data generating network models? Secondly, does Cronbach's alpha act as a lower bound for reliability in network models? Thirdly, investigating the lower bound theorem in more detail, is the lower bound assumption of uncorrelated errors met?

The code for data simulation is included in this repository in two parts: Sum_score_sim and Error_cor_sim. Sum_score_sim was used to generate all networks and data for sub-questions 1 and 2, and Error_cor_sim calculates error correlations from these networks for sub-question 3. In this code segment for 5-node networks we did not investigate sub-question 3. 

The data used in this file is data from 5-node networks. Files for 10 and 15-node networks are also included in the repository.

## Data assembly

```{r}
# load data
data_5 <- read.table("~/BDS-Master/Master thesis/R/Sim_data/Simulation_5_new.txt",
                   header = TRUE, sep = "")

# change Sw_0 edge weights
## SW_0 has no edges .: edge weight indication is misleading
data_5[data_5$model == "SW_0", "meanWeight"] <- 0

# reduce column number
## save thresholds as a 1x10 matrix
data_5 <- data_5 %>%
  rowwise() %>%
  mutate(tholds = matrix(c(tholds.1, tholds.2, tholds.3,  tholds.4, tholds.5),
                         nrow = 1),
         .keep = "unused")
## save configurations as a 1x10 matrix
data_5 <- data_5 %>%
  rowwise() %>%
  mutate(config_o = matrix(c(config_o.1, config_o.2, config_o.3,  config_o.4, 
                             config_o.5),
                           nrow = 1), 
         .keep = "unused")

# numeric connectivity
connectivity <- function(model) {
  if (model %in% c("CW", "SW_100")) {
    con <- 1
  } else if (model == "SW_75") {
    con <- 0.75
  } else if (model == "SW_50") {
    con <- 0.5
  } else if (model == "SW_25") {
    con <- 0.25
  } else {
    con <- 0
  }
  return(con)
}

data_5 <- data_5 %>% mutate(con = connectivity(model))
```

We also create a data frame that alters certain columns, which are used to create our plots.

```{r}
# create data for plots
data_5_plot <- data_5

# making factor variables
## these become the labels in the facet grid
data_5_plot$encoding <- factor(data_5$encoding,
                             levels = c(-1, 0),
                             labels = paste0(c("Symmetric", "Binary"), " Encoding"))

data_5_plot$model <- factor(data_5$model,
                          levels = c("CW", "SW_100", "SW_50", "SW_0"),
                          labels = c("CW", "SW_100", "SW_50", "SW_0"))

data_5_plot$factorThresholds <- factor(data_5$thresholds,
                               levels = c(-3, -2, -1, 0, 1),
                               labels = paste0("\u03c4", ": ", c(-3, -2, -1, 0, 1)))

data_5_plot$factorWeight <- factor(data_5$meanWeight,
                                 levels = c(0, 0.25, 0.5, 0.75, 1),
                                 labels = paste0("\u03c9: ", c(0, 0.25, 0.5, 0.75, 1)))
```


## Inspect variation 

First we will have a look at the amount of variation of the observed and expected sum scores of each of our conditions.

```{r}
# calculate variation per condition
condition_cols <- c("model", "encoding", "thresholds", "meanWeight")
data_5 %>%
  group_by(across(all_of(condition_cols))) %>%
  summarize(sd_o = sd(sum_o),
            min_o = min(sum_o),
            max_o = max(sum_o)) %>%
  arrange(encoding, desc(sd_o))

# calculate variation averaging over thresholds
data_5 %>%
  group_by(across(all_of(c("model", "encoding", "meanWeight")))) %>%
  summarize(sd_o = sd(sum_o),
            min_o = min(sum_o),
            max_o = max(sum_o)) %>%
  arrange(encoding, desc(sd_o))

# calculate variation averaging over weights
data_5 %>%
  group_by(across(all_of(c("model", "encoding", "thresholds")))) %>%
  summarize(sd_o = sd(sum_o),
            min_o = min(sum_o),
            max_o = max(sum_o)) %>%
  arrange(encoding, desc(sd_o))
```

This is easier to inspect visually, so we will plot our observed and expected sum scores per condition.

```{r}
# observed  sum score
graphs_sum_o_5 <- list()
for (enc in sort(unique(data_5_plot$encoding))){
  sub <- data_5_plot %>% filter(encoding == enc)

  graphs_sum_o_5 <- c(graphs_sum_o_5, list(
    ggplot(sub, aes(x = sum_o, fill = model)) +
      geom_histogram() +
      facet_grid(factorWeight ~ factorThresholds) +
      scale_x_continuous(breaks = seq(-5, 5, by = 5),
                     minor_breaks = seq(-5, 5, by = 1)) +
      scale_y_continuous(trans = "log10") +
      scale_fill_manual(values = c("#D55E00", "#E69F00",
                                   "#0072B2", "#CC79A7")) +
      theme_bw() +
      ggtitle(enc) +
      labs(x = "Observed Sum Score", y = "Frequency", fill = "Model") +
      theme(legend.position = "none",
            strip.text = element_text(size = 12),
            axis.text = element_text(size = 12),
            axis.title = element_text(size = 14),
            plot.title = element_text(size = 14))
  ))
}

# combine plots
graphs_sum_o_5[[1]] + graphs_sum_o_5[[2]] +
  plot_layout(nrow = 2, guides = "collect") &
  theme(legend.position = 'bottom') &
  guides(fill = guide_legend(nrow = 1))
```


## Sub-question 1: Under what conditions are the current and expected sum score related?

```{r}
# calculate correlation over all conditions
cor(data_5$sum_e, data_5$sum_o)
data_5 %>% group_by(encoding) %>% summarise(corr = cor(sum_e, sum_o))
data_5 %>%
  group_by(across(all_of(c("encoding", "meanWeight")))) %>%
  summarise(corr = cor(sum_e, sum_o)) %>%
  arrange(encoding, desc(corr))

# plot correlation over all condition
ggplot(data_5_plot,
       aes(x = sum_o, y = sum_e)) +
  geom_point() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(cols = vars(encoding), scales = "free") +
  theme_bw() +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")

# add jitter to see amount of points more clearly
# add jitter to see amount of points more clearly
ggplot(data_5_plot,
       aes(x = sum_o, y = sum_e)) +
  geom_jitter() +
  scale_x_continuous(breaks = seq(-5, 5, by = 5),
                     minor_breaks = seq(-5, 5, by = 1)) +
  facet_grid(cols = vars(encoding), scales = "free") +
  theme_bw() +
  theme(strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14)) +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")

# inspect plots at lower edge weights
ggplot(data_5_plot[data_5_plot$encoding == "Symmetric Encoding",],
       aes(x = sum_o, y = sum_e)) +
  geom_jitter() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(rows = vars(paste0("\u03c9: ", meanWeight)), scales = "free") +
  theme_bw() +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")

ggplot(data_5_plot[data_5_plot$encoding == "Symmetric Encoding",],
       aes(x = sum_o, y = sum_e)) +
  geom_jitter() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(rows = vars(paste0("con: ", con)), scales = "free") +
  theme_bw() +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")

ggplot(data_5_plot[data_5_plot$encoding == "Symmetric Encoding",],
       aes(x = sum_o, y = sum_e)) +
  geom_jitter() +
  scale_x_continuous(breaks = seq(-10, 10, by = 5),
                     minor_breaks = seq(-10, 10, by = 1)) +
  facet_grid(paste0("con: ", con) ~ paste0("\u03c9: ", meanWeight), scales = "free") +
  theme_bw() +
  xlab("Observed Sum Score") +
  ylab("Expected Sum Score")
```

This is a look into the correlation between the observed and expected sum score. The jitter on the second graph helps see the amount of points more clearly, although observes sum scores can only have integer values as demonstrated in the first plot.

```{r}
# correlation table
condition_cols <- c("model", "encoding", "factorThresholds", "meanWeight")
cor_5<- data_5_plot %>%
  group_by(across(all_of(condition_cols))) %>%
  summarize(corr = cor(sum_e, sum_o),
            thresholds = mean(thresholds), # we want to keep the threshold column
            con = mean(con),
            size = 5) %>%
  arrange(desc(corr))
cor_5
```

Let's investigate these correlations further.

```{r, warnings = FALSE}
# plot correlation per condition
ggplot(cor_5,
       aes(x = meanWeight, y = corr, colour = model)) +
  geom_line() +
  geom_point() +
  facet_grid(factorThresholds ~ encoding) +
  geom_segment(aes(y = corr, x = 0, xend = 1, yend = corr),
               data = cor_5[cor_5$model == "SW_0",]) +
  #theme(legend.position = "bottom") +
  scale_color_manual(values = c("#D55E00", "#E69F00",
                                "#0072B2", "#CC79A7")) +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.25)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2),
                     minor_breaks = seq(0, 1, by = 0.1)) +
  xlab("Edge weight") +
  ylab("Correlation")
```

Let's average over some conditions to see the effects of thresholds and weights in isolation.

```{r}
# correlation averaging over thresholds
cor_5_w <- data_5_plot %>%
  group_by(across(all_of(c("model", "encoding", "meanWeight")))) %>%
  summarize(corr = cor(sum_e, sum_o)) %>%
  arrange(desc(corr))

# plot
cor_5_plots <- list()
cor_5_plots[[1]] <- ggplot(cor_5_w,
                         aes(x = meanWeight, y = corr, colour = model)) +
  geom_line() +
  geom_point() +
  facet_grid(cols = vars(encoding), scales = "free") +
  geom_segment(aes(y = corr, x = 0, xend = 1, yend = corr),
               data = cor_5_w[cor_5_w$model == "SW_0",], color = "#CC79A7") +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.25)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2),
                     minor_breaks = seq(0, 1, by = 0.1)) +
  scale_color_manual(values = c("#D55E00", "#E69F00",
                                "#0072B2", "#CC79A7")) +
  labs(x = "Edge weight", y = "Correlation", color = "Model") +
  theme(legend.position = "none", 
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))


# correlation averaging over weights
cor_5_t <- data_5_plot %>%
  group_by(across(all_of(c("model", "encoding", "thresholds")))) %>%
  summarize(corr = cor(sum_e, sum_o)) %>%
  arrange(desc(corr))

# plot
cor_5_plots[[2]] <- ggplot(cor_5_t,
                         aes(x = thresholds, y = corr, colour = model)) +
  geom_line() +
  geom_point() +
  facet_grid(cols = vars(encoding), scales = "free") +
  theme_bw() +
  scale_x_continuous(breaks = seq(-3, 1, by = 1)) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.2),
                     minor_breaks = seq(0, 1, by = 0.1)) +
  scale_color_manual(values = c("#D55E00", "#E69F00",
                                "#0072B2", "#CC79A7")) +
  labs(x = "Thresholds", y = "Correlation", color = "Model") +
  theme(legend.position = "none", 
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

# combine plots
cor_5_plots[[1]] + cor_5_plots[[2]] +
  plot_layout(nrow = 2, guides = "collect") &
  theme(legend.position = 'bottom') &
  guides(color = guide_legend(nrow = 1))
```

## Sub-question 2: under what conditions does cronbach’s alpha hold as a lower bound for reliability?

We first create a data frame that includes statistics such as reliability, Cronbach's alpha, and overshoot. Overshoot is the amount by which alpha overestimates reliabiity.

```{r}
# calculate reliability
rel_5 <- data_5_plot %>%
  group_by(across(all_of(condition_cols))) %>%
  summarize(reliability = cor(sum_e, sum_o) ^ 2,
            alpha = cronbach.alpha(data.frame(config_o))$alpha, 
            overshoot = alpha - reliability,
            lower_bound = alpha <= reliability,
            thresholds = mean(thresholds), # keep the threshold column
            con = mean(con), # keep the connectivity column
            size = 5) %>%
  arrange(desc(overshoot))

# reliability ranges
rel_5[, "reliability"] %>% range(na.rm = TRUE)
rel_5[, "alpha"] %>% range(na.rm = TRUE)

# box plot
ggplot(rel_5, aes(y = encoding, x = reliability)) + 
  geom_boxplot() +
  theme_bw() +
  labs(x = "Reliability", y = "Encoding") +
  theme(axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

# inspect lower bound condition met
rel_5 %>% filter(!is.na(lower_bound))
```

Let's average over some conditions to see the effects of thresholds and weights in isolation.

```{r}
# calculate reliability average over thresholds
rel_5_w <- data_5_plot %>%
  group_by(across(all_of(c("model", "encoding", "meanWeight")))) %>%
  summarize(reliability = cor(sum_e, sum_o) ^ 2,
            alpha = cronbach.alpha(data.frame(config_o))$alpha, 
            overshoot = alpha - reliability,
            lower_bound = alpha <= reliability) %>%
  arrange(desc(overshoot))

# reliability ranges
rel_5_w[, "reliability"] %>% range(na.rm = TRUE)
rel_5_w[, "alpha"] %>% range(na.rm = TRUE)

# inspect lower bound condition met
rel_5_w %>% filter(!is.na(lower_bound))

# calculate reliability average over thresholds
rel_5_t <- data_5_plot %>%
  group_by(across(all_of(c("model", "encoding", "thresholds")))) %>%
  summarize(reliability = cor(sum_e, sum_o) ^ 2,
            alpha = cronbach.alpha(data.frame(config_o))$alpha, 
            overshoot = alpha - reliability,
            lower_bound = alpha <= reliability) %>%
  arrange(desc(overshoot))

# reliability ranges
rel_5_t[, "reliability"] %>% range(na.rm = TRUE)
rel_5_t[, "alpha"] %>% range(na.rm = TRUE)

# inspect lower bound condition met
rel_5_t %>% filter(!is.na(lower_bound))
```

Let's plot this for a closer look at the trends.

```{r}
ggplot(rel_5[!is.na(rel_5$reliability), ],
       aes(x = meanWeight, y = overshoot, colour = model)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0, linewidth = .8) +
  facet_grid(factorThresholds ~ encoding) +
  geom_segment(aes(y = overshoot, x = 0, xend = 1, yend = overshoot),
               data = rel_5[rel_5$model == "SW_0",]) +
  theme(legend.position = "bottom") +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.25)) +
  scale_y_continuous(breaks = seq(-1, 3, by = 1),
                     minor_breaks = seq(-1, 3, by = 0.5)) +
  xlab("Edge weight") +
  ylab("Reliability - alpha")
```

As before we inspect the influence of weights and thresholds separately.

```{r}
rel_5_plots <- list()
rel_5_plots[[1]] <- ggplot(rel_5_w,
                         aes(x = meanWeight, y = overshoot, colour = model)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0, linewidth = .8) +
  facet_grid(cols = vars(encoding), scales = "free") +
  geom_segment(aes(y = overshoot, x = 0, xend = 1, yend = overshoot),
               data = rel_5_w[rel_5_w$model == "SW_0",], color = "#CC79A7") +
  theme_bw() +
  scale_x_continuous(breaks = seq(0, 1, by = 0.25)) +
  scale_y_continuous(breaks = seq(-1, 1, by = 0.5),
                     minor_breaks = seq(-1, 1, by = 0.2)) +
      scale_color_manual(values = c("#D55E00", "#E69F00",
                                   "#0072B2", "#CC79A7")) +
  theme_bw() +
  labs(x = "Edge Weight", y = "Overshoot", color = "Model") +
  theme(legend.position = "none",
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

rel_5_plots[[2]] <- ggplot(rel_5_t,
                         aes(x = thresholds, y = overshoot, colour = model)) +
  geom_line() +
  geom_point() +
  geom_hline(yintercept = 0, linewidth = .8) +
  facet_grid(cols = vars(encoding), scales = "free") +
  theme_bw() +
  scale_x_continuous(breaks = seq(-3, 1, by = 1)) +
  scale_y_continuous(breaks = seq(-1, 1, by = 0.5),
                     minor_breaks = seq(-1, 1, by = 0.2)) +
      scale_color_manual(values = c("#D55E00", "#E69F00",
                                   "#0072B2", "#CC79A7")) +
  theme_bw() +
  labs(x = "Thresholds", y = "Overshoot", color = "Model") +
  theme(legend.position = "none",
        strip.text = element_text(size = 12),
        axis.text = element_text(size = 12),
        axis.title = element_text(size = 14))

# combine plots
rel_5_plots[[1]] + rel_5_plots[[2]] +
  plot_layout(nrow = 2, guides = "collect") &
  theme(legend.position = 'bottom') &
  guides(color = guide_legend(nrow = 1))
```
